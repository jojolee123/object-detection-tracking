 

 

 

**计算机视觉目标检测追踪实验****报告**

 

 

 

 

**实验名称：  目标检测与追踪**  

 

 

 

 



 

 

 

 

 

 

 **自动化学院**

 **2020****年5月5日**

**
**

​           

**目**  **录**



[一、总体方案设计·· - 3 -](#_Toc534379950)

[二、关键技术·· - 3 -](#_Toc534379951)

[三、源程序设计·· - 4 -](#_Toc534379953)

[四、实验结果及其评价·· - 5 -](#_Toc534379954)

[五、体会·· - 6 -](#_Toc534379955)

[六、参考文献·· - 6 -](#_Toc534379956)

 

 

 

 

 

 

​     

**
**

## 一、 总体方案设计

**总体设计：**

获取视频---目标检测---目标追踪

在用户交互界面选择要检测追踪的视频文件，对视频文件的第一帧进行目标检测，之后对各个目标进行追踪，设计过程如下：

 

**尝试实现：**

\1.    一开始我们用HOG+SVM[1]做行人检测，使用质心追踪器来完成行人跟踪(HOG特征与质心追踪器自己实现)。

\2.    我们以INRIA行人数据集[2]为基础，自己制作了128×64大小的数据集，其中有正样本3542个，负样本4146个。将7688个样本混合打乱后提取hog特征，用此训练一个SVM模型。

\3.    测试时采用滑动窗方法对视频第一帧提取HOG特征，用SVM来做判断窗口内部是否包含行人目标，再通过非极大值抑制去除误检窗口，剩下的目标就赋予它唯一的ID，在之后的图像序列中对每一帧图像都做相同的处理，得到每一帧图像中的目标的ID，再依据质心追踪器进行追踪，即相邻两帧相距最近即判定为是同一个目标，还可以实现目标的添加和注销。

\4.    但是在实验中我们发现基于这种方法来做的话，不能保证尺度不变性，即图像中用来获取HOG特征的滑动窗的大小是固定的，导致单帧图像的查准率和查全率都很低，后来我们尝试建立高斯金字塔来实现尺度不变性，但在实际使用中发现这样会导致检测单帧图像较慢，不能保证实时性。

 

**最终实现****：**

\5.    使用深度学习模型和相关滤波的方法来进行目标检测与跟踪。

\6.    我们使用yolov2[3]来实现行人的检测，模型来自官方在coco数据集上预训练好的模型。

\7.    目标追踪使用KCF[4]或者MOSSE[5]滤波器（自己实现）， KCF追踪器即核化相关滤波器，是一种鉴别式追踪方法，在追踪过程中训练一个目标检测器，使用目标检测器去检测下一帧预测位置是否是目标，然后再使用新检测结果去更新训练集进而更新目标检测器。而在训练目标检测器时一般选取目标区域为正样本，目标的周围区域为负样本，当然越靠近目标的区域为正样本的可能性越大。MOSSE相关滤波跟踪器利用了相关的特性，即两个信号越相似其相关值越高。在追踪中就是找到与跟踪目标相应最大的项，就是通过互相关来定位目标当前帧所在位置的。响应图最大值对应的位置即为当前时刻预测的目标位置。

 



## 二、 关键技术

\1.    YOLO算法：该算法先将输入图像resize到一个固定的尺寸，然后将图像分为若个网格，每个单元格负责去检测那些中心点落在该格子内的目标，每个单元格会预测边界框以及边界框的置信度，这些特征通过CNN来进行提取，最终得到一个张量，通过均方差损失函数最小化来确定边界框的位置，大小和类别。最后使用非极大值抑制去除重复的边界框。

\2.    KCF算法：主要思路为在第i帧中，在当前位置附近采样训练一个回归器，这个回归器可以计算一个小窗口的响应，在第i+1帧中，在前一帧的位置附近采样，并用前述回归器计算每个采样窗口的响应，取响应值最大的采样作为本帧的位置。其中使用目标周围区域的循环矩阵采集正负样本，利用脊回归训练目标检测器，并利用循环矩阵来降低运算量。

\3.    MOSSE算法：相关滤波跟踪器就是通过互相关(cross-correlation)来定位目标当前帧所在位置的。响应图最大值对应的位置即为当前时刻预测的目标位置，利用卷积定理将在时域求相应图转化到在频域，

 

## 三、 源程序设计和运行结果

HOG + SVM方法大致分为：

\1.   数据集制作，主要为鼠标拖拽选择感兴趣区域并resize为128*64大小（见mouse_crop.py文件）

\2.   HOG特征提取：将8000张样本随机打乱并提取HOG特征存储进二进制文件（见HOG.py文件）

\3.   训练SVM模型：使用hog特征训练SVM分类器（见train.py文件）

\4.   测试：实验前期测试时发现实时性不足，所以并未设计交互界面，只可实现速度较慢的检测且准确率并不高（见test.py文件）

\5.   追踪：根据bbox的中心来追踪物体，但因为前期检测总是时好时坏的问题，导致追踪无法成功（见centroid.py文件）

 

深度学习模型+相关滤波方法大致分为以下3个模块（不包括用户交互界面的编写）：

\1.   目标检测（见object_detection.py文件）

\2.   KCF目标跟踪（见KCFTracker.py文件）

\3.   MOSSE目标追踪（见MOSSETracker.py文件）

 

**运行结果：**运行视频见media文件夹内

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

## 四、 实验结果及其评价

**实验结果：**车辆或行人基本可以被正确检测并追踪，且满足实时性的要求，用多个视频运行结果稳定，实验结果可观。

![img](file:///C:/Users/李佼佼/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg)

​                Figure 1

![img](file:///C:/Users/李佼佼/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg)

​                  Figure 2 

**评价：**处理后的程序基本可以检测出图像中的目标并准确追踪，但是我们的实验也依然有所欠缺，比如会漏掉个别目标（如Figure 1左边红色衣服女子），多个目标距离太近的话识别为1个（如Figure 2中左边的情侣）。除此之外，实验未设计交互程序时运行无卡顿，速率最高可以达到600FPS，但是当设计好交互程序，将检测与追踪放到多线程运行时，会有略微卡顿与闪烁，我们为此找了很多办法，解决了闪烁的问题，但是视频卡顿却仍然存在，这一点仍然需要继续优化。

 

## 五、 体会

实验过程中能够将书本上或者论文中学习到的算法复现是件很开心的事情，专注于算法速度的提升也是件很纯粹并且很有乐趣的事情。总的说来实验的过程很有挑战性但也极其有趣味性。并且通过此过程我们更加熟悉了python和OpenCV的使用，对计算机视觉有了更深刻的认识，在实现课程上学习到的算法时也加深了我们对算法的理解。 

 

## 六、 分工

## 六、 参考文献

[1]   Dalal N, Triggs B. Histograms of oriented gradients for human detection[C]//2005 IEEE computer society conference on computer vision and pattern recognition (CVPR'05). IEEE, 2005, 1: 886-893.

[2]   Dalal N, Triggs B. INRIA person dataset[J]. Online: http://pascal. inrialpes. fr/data/human, 2005.

[3]   Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 779-788.

[4]   Henriques J F, Caseiro R, Martins P, et al. High-speed tracking with kernelized correlation filters[J]. IEEE transactions on pattern analysis and machine intelligence, 2014, 37(3): 583-596.

[5]   Bolme D S, Beveridge J R, Draper B A, et al. Visual object tracking using adaptive correlation filters[C]//2010 IEEE computer society conference on computer vision and pattern recognition. IEEE, 2010: 2544-2550.

 